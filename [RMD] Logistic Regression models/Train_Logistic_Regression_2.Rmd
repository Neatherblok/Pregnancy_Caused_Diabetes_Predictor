---
title: "Training Logistic Regression Model 2"
author: "Ricardo de Deijn"
date: "`r Sys.Date()`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install Packages
``` {r install_pcks}
# Install not installed project packages
if(!require(pscl)) install.packages("pscl")
if(!require(Metrics)) install.packages("Metrics")
```


## Import packages
``` {r import_pcks}
# Import all necessary project pacakges
library(pscl)
library(Metrics)
```

## Load Data Files
Read the pre-split train and test CSV files and load them in two data frames, so they are able to be used in the logistic regression model.
``` {r read_csv}
# Load CSV train and test data files
train.data <- read.csv("C:\\Users\\rdede\\Documents\\GitHub\\Pregnancy_Caused_Diabetes_Predictor\\data\\train_data.csv") 
test.data <- read.csv("C:\\Users\\rdede\\Documents\\GitHub\\Pregnancy_Caused_Diabetes_Predictor\\data\\test_data.csv")
```

## Train logistic Regression Model 2
After successfully training logistic regression model 1 on a normalized subset of the best features, we will try out what the difference is with a model that is not normalized and still has all features. This model will be trained on all the features from the train data set, with Diagnosis as the dependent variable.
This model trains with family being binomial, with a logit link. The family being binomial means that the output of the model and the dependent variable will be binary value. The logit link specifies that this binary classification is a logistic regression, and it maps the probability of success to the linear predictor.
``` {r train_mdl}
# Train Logistic Regression model 2
model <- glm(Diagnosis ~.,family=binomial(link='logit'),data=train.data)
```

## Summarize Logistic Regression Model
Now that the model has been trained, we can get a summary of what the findings of the model are on the original feature set. It shows which independent features have the most value for the eventual prediction of the dependent variable. The variables with the lowest p-value and most amount of stars have the most influence on the dependent variable.
``` {r summ_mdl}
# Summarize the findings of the second Logistic Regression model
summary(model)
```

## Logistic Regression Model 2 Prediction
After that the second Logistic Regression model has been trained on the whole feature set, it can predict the values that are in the test set. It will do this through the response type which will give back a probability for the tested observation between 0 and 1. 
After all the observations are fitted, the predictions get converted to a binary value depending on the probability score. Values with a probability of 0.5 or higher gets converted to a 1 value, values under 0.5 get converted to the 0 value.
``` {r acc_mdl}
# Predict the outcome using Logistic Regression Model 2
fitted.results <- predict(model,test.data,type='response')

# Transform predicted probability values with a probability higher than 0.5 to 1
# Transform values with probability lower than 0.5 to 0
predictions <- ifelse(fitted.results >= 0.5, 1, 0)
```
## Calculate Metrics for LRM 2
After the logistic regression model predicted the values from the test set based on the whole feature set, the metrics can get calculated for this version. At first the confusion matrix and accuracy gets calculated, with the `confusionMatrix()` function from the caret package.
``` {r conf_matrix}
# Create a classification report
# This includes a confusion matrix and accuracy
classification_report <- caret::confusionMatrix(factor(predictions), factor(test.data$Diagnosis))
print(classification_report)
```

Afterwards, the Recall, Precision and F1 gets calculated to get a more precise score of how the model performed. The metrics get calculated through the usage of the `recall()`,`precision()`, and `f1()` function from the Metrics package.
``` {r f1}
# Calculate a recall score
recall <- Metrics::recall(predictions, test.data$Diagnosis)
recall
 
# Calculate a precision score
precision <- Metrics::precision(predictions, test.data$Diagnosis)
precision
 
# Calculate a f1-score
f1 <- Metrics::f1(predictions, test.data$Diagnosis)
f1
```